{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ada1910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import ydata_profiling\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74ce3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel(r'C:\\Users\\sg_cl\\Desktop\\masters subjects\\DSRT 736\\Fraud Dataset\\New_data_CCFD\\ccfraudTrain.xlsx')\n",
    "\n",
    "df1 = pd.read_excel(r'C:\\Users\\sg_cl\\Desktop\\masters subjects\\DSRT 736\\Fraud Dataset\\New_data_CCFD\\ccfraudTest.xlsx')\n",
    "# For snakey diagram\n",
    "#df1 = pd.read_excel(r'C:\\Users\\sg_cl\\Desktop\\masters subjects\\DSRT 736\\Fraud Dataset\\New_data_CCFD\\Sankey_data.xlsx')mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e678e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values:\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cec9fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count    Dtype         \n",
      "---  ------                 --------------    -----         \n",
      " 0   Unnamed: 0             1048575 non-null  int64         \n",
      " 1   trans_date_trans_time  1048575 non-null  datetime64[ns]\n",
      " 2   cc_num                 1048575 non-null  int64         \n",
      " 3   merchant               1048575 non-null  object        \n",
      " 4   category               1048575 non-null  object        \n",
      " 5   amt                    1048575 non-null  float64       \n",
      " 6   first                  1048575 non-null  object        \n",
      " 7   last                   1048575 non-null  object        \n",
      " 8   gender                 1048575 non-null  object        \n",
      " 9   street                 1048575 non-null  object        \n",
      " 10  city                   1048575 non-null  object        \n",
      " 11  state                  1048575 non-null  object        \n",
      " 12  zip                    1048575 non-null  int64         \n",
      " 13  lat                    1048575 non-null  float64       \n",
      " 14  long                   1048575 non-null  float64       \n",
      " 15  city_pop               1048575 non-null  int64         \n",
      " 16  job                    1048575 non-null  object        \n",
      " 17  dob                    1048575 non-null  datetime64[ns]\n",
      " 18  trans_num              1048575 non-null  object        \n",
      " 19  unix_time              1048575 non-null  int64         \n",
      " 20  merch_lat              1048575 non-null  float64       \n",
      " 21  merch_long             1048575 non-null  float64       \n",
      " 22  is_fraud               1048575 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(5), int64(6), object(10)\n",
      "memory usage: 184.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 555719 entries, 0 to 555718\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   Unnamed: 0             555719 non-null  int64         \n",
      " 1   trans_date_trans_time  555719 non-null  datetime64[ns]\n",
      " 2   cc_num                 555719 non-null  int64         \n",
      " 3   merchant               555719 non-null  object        \n",
      " 4   category               555719 non-null  object        \n",
      " 5   amt                    555719 non-null  float64       \n",
      " 6   first                  555719 non-null  object        \n",
      " 7   last                   555719 non-null  object        \n",
      " 8   gender                 555719 non-null  object        \n",
      " 9   street                 555719 non-null  object        \n",
      " 10  city                   555719 non-null  object        \n",
      " 11  state                  555719 non-null  object        \n",
      " 12  zip                    555719 non-null  int64         \n",
      " 13  lat                    555719 non-null  float64       \n",
      " 14  long                   555719 non-null  float64       \n",
      " 15  city_pop               555719 non-null  int64         \n",
      " 16  job                    555719 non-null  object        \n",
      " 17  dob                    555719 non-null  datetime64[ns]\n",
      " 18  trans_num              555719 non-null  object        \n",
      " 19  unix_time              555719 non-null  int64         \n",
      " 20  merch_lat              555719 non-null  float64       \n",
      " 21  merch_long             555719 non-null  float64       \n",
      " 22  is_fraud               555719 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(5), int64(6), object(10)\n",
      "memory usage: 97.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>amt</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>555719.000000</td>\n",
       "      <td>5.557190e+05</td>\n",
       "      <td>555719.000000</td>\n",
       "      <td>555719.000000</td>\n",
       "      <td>555719.000000</td>\n",
       "      <td>555719.000000</td>\n",
       "      <td>5.557190e+05</td>\n",
       "      <td>5.557190e+05</td>\n",
       "      <td>555719.000000</td>\n",
       "      <td>555719.000000</td>\n",
       "      <td>555719.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>277859.000000</td>\n",
       "      <td>4.178387e+17</td>\n",
       "      <td>69.392810</td>\n",
       "      <td>48842.628015</td>\n",
       "      <td>38.543253</td>\n",
       "      <td>-90.231325</td>\n",
       "      <td>8.822189e+04</td>\n",
       "      <td>1.380679e+09</td>\n",
       "      <td>38.542798</td>\n",
       "      <td>-90.231380</td>\n",
       "      <td>0.003860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>160422.401459</td>\n",
       "      <td>1.309837e+18</td>\n",
       "      <td>156.745941</td>\n",
       "      <td>26855.283328</td>\n",
       "      <td>5.061336</td>\n",
       "      <td>13.721780</td>\n",
       "      <td>3.003909e+05</td>\n",
       "      <td>5.201104e+06</td>\n",
       "      <td>5.095829</td>\n",
       "      <td>13.733071</td>\n",
       "      <td>0.062008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.041621e+10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>20.027100</td>\n",
       "      <td>-165.672300</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.371817e+09</td>\n",
       "      <td>19.027422</td>\n",
       "      <td>-166.671575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>138929.500000</td>\n",
       "      <td>1.800429e+14</td>\n",
       "      <td>9.630000</td>\n",
       "      <td>26292.000000</td>\n",
       "      <td>34.668900</td>\n",
       "      <td>-96.798000</td>\n",
       "      <td>7.410000e+02</td>\n",
       "      <td>1.376029e+09</td>\n",
       "      <td>34.755301</td>\n",
       "      <td>-96.905129</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>277859.000000</td>\n",
       "      <td>3.521417e+15</td>\n",
       "      <td>47.290000</td>\n",
       "      <td>48174.000000</td>\n",
       "      <td>39.371600</td>\n",
       "      <td>-87.476900</td>\n",
       "      <td>2.408000e+03</td>\n",
       "      <td>1.380762e+09</td>\n",
       "      <td>39.376593</td>\n",
       "      <td>-87.445204</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>416788.500000</td>\n",
       "      <td>4.635331e+15</td>\n",
       "      <td>83.010000</td>\n",
       "      <td>72011.000000</td>\n",
       "      <td>41.894800</td>\n",
       "      <td>-80.175200</td>\n",
       "      <td>1.968500e+04</td>\n",
       "      <td>1.385867e+09</td>\n",
       "      <td>41.954163</td>\n",
       "      <td>-80.264637</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>555718.000000</td>\n",
       "      <td>4.992346e+18</td>\n",
       "      <td>22768.110000</td>\n",
       "      <td>99921.000000</td>\n",
       "      <td>65.689900</td>\n",
       "      <td>-67.950300</td>\n",
       "      <td>2.906700e+06</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>66.679297</td>\n",
       "      <td>-66.952026</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0        cc_num            amt            zip  \\\n",
       "count  555719.000000  5.557190e+05  555719.000000  555719.000000   \n",
       "mean   277859.000000  4.178387e+17      69.392810   48842.628015   \n",
       "std    160422.401459  1.309837e+18     156.745941   26855.283328   \n",
       "min         0.000000  6.041621e+10       1.000000    1257.000000   \n",
       "25%    138929.500000  1.800429e+14       9.630000   26292.000000   \n",
       "50%    277859.000000  3.521417e+15      47.290000   48174.000000   \n",
       "75%    416788.500000  4.635331e+15      83.010000   72011.000000   \n",
       "max    555718.000000  4.992346e+18   22768.110000   99921.000000   \n",
       "\n",
       "                 lat           long      city_pop     unix_time  \\\n",
       "count  555719.000000  555719.000000  5.557190e+05  5.557190e+05   \n",
       "mean       38.543253     -90.231325  8.822189e+04  1.380679e+09   \n",
       "std         5.061336      13.721780  3.003909e+05  5.201104e+06   \n",
       "min        20.027100    -165.672300  2.300000e+01  1.371817e+09   \n",
       "25%        34.668900     -96.798000  7.410000e+02  1.376029e+09   \n",
       "50%        39.371600     -87.476900  2.408000e+03  1.380762e+09   \n",
       "75%        41.894800     -80.175200  1.968500e+04  1.385867e+09   \n",
       "max        65.689900     -67.950300  2.906700e+06  1.388534e+09   \n",
       "\n",
       "           merch_lat     merch_long       is_fraud  \n",
       "count  555719.000000  555719.000000  555719.000000  \n",
       "mean       38.542798     -90.231380       0.003860  \n",
       "std         5.095829      13.733071       0.062008  \n",
       "min        19.027422    -166.671575       0.000000  \n",
       "25%        34.755301     -96.905129       0.000000  \n",
       "50%        39.376593     -87.445204       0.000000  \n",
       "75%        41.954163     -80.264637       0.000000  \n",
       "max        66.679297     -66.952026       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# checking the dataset\n",
    "df.info()\n",
    "df.describe()\n",
    "df1.info()\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8c636f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
      "0           0   2019-01-01 00:00:18  2703186189652090   \n",
      "1           1   2019-01-01 00:00:44      630423337322   \n",
      "2           2   2019-01-01 00:00:51    38859492057661   \n",
      "3           3   2019-01-01 00:01:16  3534093764340240   \n",
      "4           4   2019-01-01 00:03:06   375534208663984   \n",
      "\n",
      "                             merchant       category     amt      first  \\\n",
      "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
      "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
      "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
      "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
      "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
      "\n",
      "      last gender                        street            city state    zip  \\\n",
      "0    Banks      F                561 Perry Cove  Moravian Falls    NC  28654   \n",
      "1     Gill      F  43039 Riley Greens Suite 393          Orient    WA  99160   \n",
      "2  Sanchez      M      594 White Dale Suite 530      Malad City    ID  83252   \n",
      "3    White      M   9443 Cynthia Court Apt. 038         Boulder    MT  59632   \n",
      "4   Garcia      M              408 Bradley Rest        Doe Hill    VA  24433   \n",
      "\n",
      "       lat      long  city_pop                                job        dob  \\\n",
      "0  36.0788  -81.1781      3495          Psychologist, counselling 1988-03-09   \n",
      "1  48.8878 -118.2105       149  Special educational needs teacher 1978-06-21   \n",
      "2  42.1808 -112.2620      4154        Nature conservation officer 1962-01-19   \n",
      "3  46.2306 -112.1138      1939                    Patent attorney 1967-01-12   \n",
      "4  38.4207  -79.4629        99     Dance movement psychotherapist 1986-03-28   \n",
      "\n",
      "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
      "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
      "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
      "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
      "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
      "\n",
      "   is_fraud trans_date_trans_time_HR             unix_time_NEW  \n",
      "0         0                       00 2011-12-31 14:00:18-05:00  \n",
      "1         0                       00 2011-12-31 14:00:44-05:00  \n",
      "2         0                       00 2011-12-31 14:00:51-05:00  \n",
      "3         0                       00 2011-12-31 14:01:16-05:00  \n",
      "4         0                       00 2011-12-31 14:03:06-05:00  \n",
      "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
      "0           0   2020-06-21 12:14:25  2291163933867240   \n",
      "1           1   2020-06-21 12:14:33  3573030041201290   \n",
      "2           2   2020-06-21 12:14:53  3598215285024750   \n",
      "3           3   2020-06-21 12:15:15  3591919803438420   \n",
      "4           4   2020-06-21 12:15:17  3526826139003040   \n",
      "\n",
      "                               merchant        category    amt   first  \\\n",
      "0                 fraud_Kirlin and Sons   personal_care   2.86    Jeff   \n",
      "1                  fraud_Sporer-Keebler   personal_care  29.84  Joanne   \n",
      "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28  Ashley   \n",
      "3                     fraud_Haley Group        misc_pos  60.05   Brian   \n",
      "4                 fraud_Johnston-Casper          travel   3.19  Nathan   \n",
      "\n",
      "       last gender                       street        city state    zip  \\\n",
      "0   Elliott      M            351 Darlene Green    Columbia    SC  29209   \n",
      "1  Williams      F             3638 Marsh Union     Altonah    UT  84002   \n",
      "2     Lopez      F         9333 Valentine Point    Bellmore    NY  11710   \n",
      "3  Williams      M  32941 Krystal Mill Apt. 552  Titusville    FL  32780   \n",
      "4    Massey      M     5783 Evan Roads Apt. 465    Falmouth    MI  49632   \n",
      "\n",
      "       lat      long  city_pop                     job        dob  \\\n",
      "0  33.9659  -80.9355    333497     Mechanical engineer 1968-03-19   \n",
      "1  40.3207 -110.4360       302  Sales professional, IT 1990-01-17   \n",
      "2  40.6729  -73.5365     34496       Librarian, public 1970-10-21   \n",
      "3  28.5697  -80.8191     54767            Set designer 1987-07-25   \n",
      "4  44.2529  -85.0170      1126      Furniture designer 1955-07-06   \n",
      "\n",
      "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0  2da90c7d74bd46a0caf3777415b3ebd3  1371816865  33.986391  -81.200714   \n",
      "1  324cc204407e99f51b0d6ca0055005e7  1371816873  39.450498 -109.960431   \n",
      "2  c81755dbbbea9d5c77f094348a7579be  1371816893  40.495810  -74.196111   \n",
      "3  2159175b9efe66dc301f149d3d5abf8c  1371816915  28.812398  -80.883061   \n",
      "4  57ff021bd3f328f8738bb535c302a31b  1371816917  44.959148  -85.884734   \n",
      "\n",
      "   is_fraud trans_date_trans_time_HR             unix_time_NEW  \n",
      "0         0                       12 2013-06-21 04:14:25-04:00  \n",
      "1         0                       12 2013-06-21 04:14:33-04:00  \n",
      "2         0                       12 2013-06-21 04:14:53-04:00  \n",
      "3         0                       12 2013-06-21 04:15:15-04:00  \n",
      "4         0                       12 2013-06-21 04:15:17-04:00  \n"
     ]
    }
   ],
   "source": [
    "#print (df['trans_date_trans_time'].head())\n",
    "from datetime import datetime as dt\n",
    "import pytz  # Import the pytz module for time zones\n",
    "\n",
    "df['trans_date_trans_time_HR'] = df['trans_date_trans_time'].dt.strftime(\"%H\")\n",
    "\n",
    "# Convert the Unix time values to datetime objects\n",
    "df['unix_time_NEW'] = df['unix_time'].apply(lambda x: dt.fromtimestamp(x))\n",
    "\n",
    "# Set the time zone to the desired time zone (e.g., 'UTC' or your local time zone)\n",
    "local_time_zone = 'America/New_York'\n",
    "df['unix_time_NEW'] = df['unix_time_NEW'].dt.tz_localize(pytz.utc).dt.tz_convert(local_time_zone)\n",
    "\n",
    "\n",
    "print (df.head())\n",
    "\n",
    "df1['trans_date_trans_time_HR'] = df1['trans_date_trans_time'].dt.strftime(\"%H\")\n",
    "\n",
    "# Convert the Unix time values to datetime objects\n",
    "df1['unix_time_NEW'] = df1['unix_time'].apply(lambda x: dt.fromtimestamp(x))\n",
    "\n",
    "# Set the time zone to the desired time zone (e.g., 'UTC' or your local time zone)\n",
    "local_time_zone = 'America/New_York'\n",
    "df1['unix_time_NEW'] = df1['unix_time_NEW'].dt.tz_localize(pytz.utc).dt.tz_convert(local_time_zone)\n",
    "\n",
    "\n",
    "print (df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d1f030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('unix_time', axis=1)\n",
    "df = df.drop('unix_time_NEW', axis=1)\n",
    "df1 = df1.drop('unix_time', axis=1)\n",
    "df1 = df1.drop('unix_time_NEW', axis=1)\n",
    "#df = df.drop('Errors?', axis=1)\n",
    "#df = df.drop('Time', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b43a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f965c904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unnamed: 0    cc_num       amt       zip       lat      long  \\\n",
      "Unnamed: 0    1.000000  0.000575 -0.001397  0.001207 -0.000781 -0.001047   \n",
      "cc_num        0.000575  1.000000  0.000760  0.041448 -0.058910 -0.047945   \n",
      "amt          -0.001397  0.000760  1.000000  0.001567 -0.001916  0.000151   \n",
      "zip           0.001207  0.041448  0.001567  1.000000 -0.113957 -0.909957   \n",
      "lat          -0.000781 -0.058910 -0.001916 -0.113957  1.000000 -0.016041   \n",
      "long         -0.001047 -0.047945  0.000151 -0.909957 -0.016041  1.000000   \n",
      "city_pop     -0.000856 -0.008993  0.006485  0.079164 -0.156069 -0.053443   \n",
      "merch_lat    -0.000690 -0.058611 -0.001832 -0.113250  0.993598 -0.015967   \n",
      "merch_long   -0.001045 -0.047925  0.000156 -0.909147 -0.016033  0.999120   \n",
      "is_fraud     -0.009041 -0.002301  0.218417 -0.001844  0.001355  0.002030   \n",
      "\n",
      "            city_pop  merch_lat  merch_long  is_fraud  \n",
      "Unnamed: 0 -0.000856  -0.000690   -0.001045 -0.009041  \n",
      "cc_num     -0.008993  -0.058611   -0.047925 -0.002301  \n",
      "amt         0.006485  -0.001832    0.000156  0.218417  \n",
      "zip         0.079164  -0.113250   -0.909147 -0.001844  \n",
      "lat        -0.156069   0.993598   -0.016033  0.001355  \n",
      "long       -0.053443  -0.015967    0.999120  0.002030  \n",
      "city_pop    1.000000  -0.155174   -0.053423  0.001824  \n",
      "merch_lat  -0.155174   1.000000   -0.015961  0.001212  \n",
      "merch_long -0.053423  -0.015961    1.000000  0.002055  \n",
      "is_fraud    0.001824   0.001212    0.002055  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
       "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
       "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'merch_lat',\n",
       "       'merch_long', 'is_fraud', 'trans_date_trans_time_HR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.corr())\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce5a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pandas_profiling.ProfileReport(df)\n",
    "df['trans_date_trans_time_HR'].unique()\n",
    "profile.to_file(\"data_profile_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf90d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "profile.to_file(\"data_profile_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681704a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4400ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset 1\n",
    "# Convert 'Timestamp' column to datetime type\n",
    "#main_df['Timestamp'] = pd.to_datetime(main_df['Timestamp'])\n",
    "\n",
    "# Select the desired columns and perform aggregation on the subset\n",
    "subset_df = df[[ 'cc_num', 'trans_date_trans_time_HR', 'merchant', 'category', 'gender','state','lat', 'long','merch_lat',\n",
    "       'merch_long', 'amt','is_fraud']].reset_index()\n",
    "subset_df1 = df1[[ 'cc_num', 'trans_date_trans_time_HR', 'merchant', 'category', 'gender','state','lat', 'long','merch_lat',\n",
    "       'merch_long', 'amt','is_fraud']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3c6bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e5fe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "subset_df = pd.get_dummies(subset_df, columns=['merchant', 'category', 'gender', 'state'])\n",
    "\n",
    "subset_df1 = pd.get_dummies(subset_df1, columns=['merchant', 'category', 'gender', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaacd48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset_df.head()\n",
    "subset_df = subset_df.drop('state_DE', axis=1)\n",
    "#subset_df1.head()\n",
    "#subset_df1['state_DE'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd38b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data pre processing String values to Int values\n",
    "print(df['Is Fraud?'].unique())\n",
    "y = df['Is Fraud?']\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc.fit(y)\n",
    "y = enc.transform(y)\n",
    "print(y)\n",
    "\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = df.drop('Is Fraud?', axis=1)\n",
    "print(X.head())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec48a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features (X) and target (y)\n",
    "X = subset_df.drop('is_fraud', axis=1)\n",
    "y = subset_df['is_fraud']\n",
    "\n",
    "X1 = subset_df1.drop('is_fraud', axis=1)\n",
    "y1 = subset_df1['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values:\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b49e89f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "X_train,X_test, y_train,y_test = train_test_split(X, y,test_size=0.2, stratify=y, random_state=42)\n",
    "#X_val,X_test,y_val, y_test = train_test_split(X1, y1,test_size=0.5, stratify=y1, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5daf404a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (838860, 767) (838860,)\n",
      "Test set shape: (209715, 767) (209715,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the resulting subsets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "946331dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model\n",
    "# = LinearRegression()\n",
    "# Define class weights (adjust these based on your problem)\n",
    "genuine_weight = 1.0 #6006 / (1042569 + 6006)\n",
    "fraud_weight = 9.0 #1042569 / (1042569 + 6006)\n",
    "\n",
    "class_weights = {0: genuine_weight, 1: fraud_weight}\n",
    "#class_weights = {0: 1.0, 1: 10.0}\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100,class_weight=class_weights, random_state=42,n_jobs=-1,max_samples=0.8)\n",
    "model1 = RandomForestClassifier(n_estimators=30,class_weight=class_weights, random_state=42,n_jobs=-1,max_samples=0.8)\n",
    "model2 = RandomForestClassifier(n_estimators=70,class_weight=class_weights, random_state=42,n_jobs=-1,max_samples=0.8)\n",
    "model3 = RandomForestClassifier(n_estimators=80,class_weight=class_weights, random_state=42,n_jobs=-1,max_samples=0.8)\n",
    "model4 = RandomForestClassifier(n_estimators=90,class_weight=class_weights, random_state=42,n_jobs=-1,max_samples=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6150a82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'cc_num', 'trans_date_trans_time_HR', 'lat', 'long',\n",
       "       'merch_lat', 'merch_long', 'amt', 'merchant_fraud_Abbott-Rogahn',\n",
       "       'merchant_fraud_Abbott-Steuber',\n",
       "       ...\n",
       "       'state_SD', 'state_TN', 'state_TX', 'state_UT', 'state_VA', 'state_VT',\n",
       "       'state_WA', 'state_WI', 'state_WV', 'state_WY'],\n",
       "      dtype='object', length=767)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf8d1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_exclude = 'is_fraud'\n",
    "X_train = subset_df.drop(columns = [cols_to_exclude])\n",
    "y_train = subset_df[['is_fraud']]\n",
    "X_test = subset_df1.drop(columns = [cols_to_exclude])\n",
    "y_test = subset_df1[['is_fraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ffb4729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sg_cl\\AppData\\Local\\Temp\\ipykernel_13436\\1300458953.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n",
      "C:\\Users\\sg_cl\\AppData\\Local\\Temp\\ipykernel_13436\\1300458953.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model1.fit(X_train, y_train)\n",
      "C:\\Users\\sg_cl\\AppData\\Local\\Temp\\ipykernel_13436\\1300458953.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model2.fit(X_train, y_train)\n",
      "C:\\Users\\sg_cl\\AppData\\Local\\Temp\\ipykernel_13436\\1300458953.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model3.fit(X_train, y_train)\n",
      "C:\\Users\\sg_cl\\AppData\\Local\\Temp\\ipykernel_13436\\1300458953.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model4.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1.0, 1: 9.0}, max_samples=0.8,\n",
       "                       n_estimators=90, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Train the model\n",
    "model1.fit(X_train, y_train)\n",
    "# Train the model\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "model4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a689cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b731ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y1_pred = model1.predict(X_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y2_pred = model2.predict(X_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y3_pred = model3.predict(X_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y4_pred = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78c281ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.002060393832134586\n",
      "Confusion Matrix:\n",
      " [[553529     45]\n",
      " [  1100   1045]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.96      0.49      0.65      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.74      0.82    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "Confusion Matrix:\n",
      " [[553521     53]\n",
      " [  1132   1013]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.47      0.63      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.74      0.81    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "Confusion Matrix:\n",
      " [[553524     50]\n",
      " [  1109   1036]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.48      0.64      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.74      0.82    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "Confusion Matrix:\n",
      " [[553528     46]\n",
      " [  1101   1044]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.96      0.49      0.65      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.74      0.82    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "Confusion Matrix:\n",
      " [[553528     46]\n",
      " [  1095   1050]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.96      0.49      0.65      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.74      0.82    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y1_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y1_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y2_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y2_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y3_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y3_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y4_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fed753b3",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Replace clf with your Random Forest model and X_test with your test data\n",
    "predicted_probabilities = model.predict_proba(X_test)[:, 1] \n",
    "predicted_probabilities1 = model1.predict_proba(X_test)[:, 1] \n",
    "predicted_probabilities2 = model2.predict_proba(X_test)[:, 1] \n",
    "predicted_probabilities3 = model3.predict_proba(X_test)[:, 1] \n",
    "predicted_probabilities4 = model4.predict_proba(X_test)[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed77812",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062b83e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]  # Example threshold values\n",
    "for threshold in thresholds:\n",
    "    y_pred = (predicted_probabilities >= threshold).astype(int)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Threshold: {threshold:.2f} | Precision: {precision:.2f} | Recall: {recall:.2f} | F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81eb25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]  # Example threshold values\n",
    "for threshold in thresholds:\n",
    "    y1_pred = (predicted_probabilities1 >= threshold).astype(int)\n",
    "    precision = precision_score(y_test, y1_pred)\n",
    "    recall = recall_score(y_test, y1_pred)\n",
    "    f1 = f1_score(y_test, y1_pred)\n",
    "    print(f\"Threshold: {threshold:.2f} | Precision: {precision:.2f} | Recall: {recall:.2f} | F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74104f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]  # Example threshold values\n",
    "for threshold in thresholds:\n",
    "    y2_pred = (predicted_probabilities2 >= threshold).astype(int)\n",
    "    precision = precision_score(y_test, y2_pred)\n",
    "    recall = recall_score(y_test, y2_pred)\n",
    "    f1 = f1_score(y_test, y2_pred)\n",
    "    print(f\"Threshold: {threshold:.2f} | Precision: {precision:.2f} | Recall: {recall:.2f} | F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aebf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]  # Example threshold values\n",
    "for threshold in thresholds:\n",
    "    y3_pred = (predicted_probabilities3 >= threshold).astype(int)\n",
    "    precision = precision_score(y_test, y3_pred)\n",
    "    recall = recall_score(y_test, y3_pred)\n",
    "    f1 = f1_score(y_test, y3_pred)\n",
    "    print(f\"Threshold: {threshold:.2f} | Precision: {precision:.2f} | Recall: {recall:.2f} | F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2598789",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.20 | Precision: 0.71 | Recall: 0.74 | F1-score: 0.72\n",
      "Confusion Matrix:\n",
      " [[552922    652]\n",
      " [   555   1590]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.71      0.74      0.72      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.85      0.87      0.86    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.2] \n",
    "#thresholds = [0.2,0.3, 0.4, 0.5, 0.6, 0.7,0.8]  # Example threshold values\n",
    "for threshold in thresholds:\n",
    "    y4_pred = (predicted_probabilities4 >= threshold).astype(int)\n",
    "    precision = precision_score(y_test, y4_pred)\n",
    "    recall = recall_score(y_test, y4_pred)\n",
    "    f1 = f1_score(y_test, y4_pred)\n",
    "    print(f\"Threshold: {threshold:.2f} | Precision: {precision:.2f} | Recall: {recall:.2f} | F1-score: {f1:.2f}\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y4_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb60269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "#X_train,X_test, y_train,y_test = train_test_split(X, y,test_size=0.2, stratify=y, random_state=42)\n",
    "X_val,X_test,y_val, y_test = train_test_split(X1, y1,test_size=0.5, stratify=y1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4a7acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y4_pred = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c8f65f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(838860, 767)\n",
      "(277860, 767)\n",
      "(838860,)\n",
      "(277860,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1911123",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [277860, 209715]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13436\\4207838902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my4_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredicted_probabilities4\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my4_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my4_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my4_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1755\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1756\u001b[0m     \"\"\"\n\u001b[1;32m-> 1757\u001b[1;33m     p, _, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[0;32m   1758\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1759\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1544\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average has to be one of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [277860, 209715]"
     ]
    }
   ],
   "source": [
    "thresholds = [0.3] \n",
    "#thresholds = [0.2,0.3, 0.4, 0.5, 0.6, 0.7,0.8]  # Example threshold values\n",
    "for threshold in thresholds:\n",
    "    y4_pred = (predicted_probabilities4 >= threshold).astype(int)\n",
    "    precision = precision_score(y_test, y4_pred)\n",
    "    recall = recall_score(y_test, y4_pred)\n",
    "    f1 = f1_score(y_test, y4_pred)\n",
    "    print(f\"Threshold: {threshold:.2f} | Precision: {precision:.2f} | Recall: {recall:.2f} | F1-score: {f1:.2f}\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y4_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afccc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, predicted_probabilities4)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f58ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predicted labels to the dataset\n",
    "X_test['predicted_label'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_totals = df.groupby('is_fraud')['is_fraud'].count()\n",
    "print(category_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8dd432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify false negative transactions\n",
    "false_negatives = X_test[(X_test['predicted_label'] == 0) & (X_test['is_fraud'] == 1)]\n",
    "print(false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153dd673",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)\n",
    "# Set a threshold\n",
    "threshold = 0.01\n",
    "\n",
    "# Convert predictions to binary classes based on the threshold\n",
    "y_pred_binary = [1 if val >= threshold else 0 for val in y_pred]\n",
    "\n",
    "# Print the binary predictions\n",
    "print(\"Binary Predictions:\", y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74955d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd14df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an example for validation (optional)\n",
    "example_index = 208\n",
    "example_features = X.iloc[example_index]\n",
    "example_target = y[example_index]\n",
    "\n",
    "# Make predictions on the example\n",
    "example_prediction = model.predict([example_features])\n",
    "\n",
    "# Compare with actual value\n",
    "print(\"Example features:\", example_features)\n",
    "print(\"Example target:\", example_target)\n",
    "print(\"Example prediction:\", example_prediction)\n",
    "\n",
    "# Calculate mean squared error on the test set (optional)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8242f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = y_pred_binary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d3e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
